Warning: Learning hooks not available, using no-op
{
  "actions": {
    "action_step_fraction": 0.9951923076923077,
    "commands": {
      "full-cycle": 207
    },
    "steps_with_action": 207,
    "total_steps": 208,
    "types": {}
  },
  "episode_stats": {
    "average_episode_length": 29.714285714285715,
    "episodes_per_run": {
      "423675f3-972e-4e9b-9e4e-af9ca3af4fec": 81,
      "88173ba5-6fa8-416a-9da3-c44d80f50fc2": 2,
      "8ffc5ed2-0f03-44da-9334-bb99979d895a": 5,
      "b04a5368-7b5c-4347-8f7f-6c873a653d44": 13,
      "e9f55471-4373-40a3-82a1-5dcb233e7cf3": 2,
      "ed86bebf-26af-4ccb-bc43-045d7f03d757": 103,
      "f0f88534-755a-40e1-92a8-6ae67f7ac7e3": 2
    },
    "total_episodes": 7
  },
  "horizon": {
    "episode_count": 7,
    "histogram": {
      "1-5": 4,
      "11-15": 1,
      "16+": 2,
      "6-10": 0
    },
    "lengths": {
      "max": 103,
      "mean": 29.714285714285715,
      "min": 2
    }
  },
  "readiness": {
    "info": [
      "Reward signal has 203 distinct values (>= 2)."
    ],
    "warnings": [
      "Low episode count: 7 (< 10). Consider collecting more data.",
      "High horizon variance: 1599.35 (> 50.0). Consider normalizing episode lengths or bucketing."
    ]
  },
  "rewards": {
    "count": 208,
    "histogram": {
      "[-0.901, -0.677)": 13,
      "[-1.12, -0.901)": 3,
      "[0.664, 0.887)": 3,
      "[0.887, 1.11)": 189
    },
    "malformed_entries": 0,
    "malformed_fraction": 0.0,
    "max": 1.1109133333333334,
    "mean": 0.9172382852564103,
    "median": 1.0683150000000001,
    "min": -1.12453,
    "total_entries": 208
  },
  "state_features": {
    "fields": {
      "average_score": {
        "count": 208,
        "fraction": 1.0
      },
      "cycle_index": {
        "count": 208,
        "fraction": 1.0
      },
      "governor_health": {
        "count": 208,
        "fraction": 1.0
      },
      "iteration_id": {
        "count": 208,
        "fraction": 1.0
      },
      "metrics": {
        "count": 208,
        "fraction": 1.0
      },
      "patterns": {
        "count": 208,
        "fraction": 1.0
      },
      "risk_distribution": {
        "count": 208,
        "fraction": 1.0
      },
      "timestamp": {
        "count": 208,
        "fraction": 1.0
      }
    },
    "total_state_steps": 208
  },
  "strict_status": {
    "malformed_fraction": 0.0,
    "strict": true,
    "tolerance": 0.01,
    "violations": [
      "Low episode count: 7 (< 10). Consider collecting more data.",
      "High horizon variance: 1599.35 (> 50.0). Consider normalizing episode lengths or bucketing."
    ]
  },
  "thresholds": {
    "max_horizon_variance": 50.0,
    "min_action_coverage": 0.1,
    "min_episodes": 10,
    "min_reward_diversity": 2
  }
}
Warning: Learning hooks not available, using no-op
