#!/usr/bin/env bash
#
# af - Agentic Flow Unified Command Interface
#
# Consolidates tool contexts into single interface to reduce friction
# and close Build-Measure-Learn feedback loops.
#
# Usage: af <command> [args]

set -euo pipefail

SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(cd "$SCRIPT_DIR/.." && pwd)"

# Global Flags
export AF_ENABLE_IRIS_METRICS="${AF_ENABLE_IRIS_METRICS:-0}"

# Check for --log-goalie flag
for arg in "$@"; do
    if [ "$arg" = "--log-goalie" ]; then
        export AF_ENABLE_IRIS_METRICS="1"
        break
    fi
done

# Colors
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
RED='\033[0;31m'
BLUE='\033[0;34m'
NC='\033[0m'

# IRIS Command (can be overridden for testing)
export AF_IRIS_CMD="${AF_IRIS_CMD:-npx iris}"

# IRIS Bridge Helper - Capture IRIS metrics to .goalie/metrics_log.jsonl
capture_iris_metrics() {
    local iris_command="$1"
    shift
    local iris_args=("$@")

    # Only capture if metrics logging is enabled
    if [ "$AF_ENABLE_IRIS_METRICS" = "1" ]; then
        local goalie_dir="$PROJECT_ROOT/.goalie"
        mkdir -p "$goalie_dir"
        # Call iris_bridge.ts via npx tsx, forcing log file under PROJECT_ROOT/.goalie
        npx -y tsx "$PROJECT_ROOT/tools/federation/iris_bridge.ts" \
            "$iris_command" "${iris_args[@]}" --log-file "$goalie_dir/metrics_log.jsonl" 2>/dev/null || \
            echo -e "${YELLOW}[iris_bridge] Warning: Failed to log IRIS metrics${NC}" >&2
    fi
}

# Pattern metrics logging helper
log_pattern_event() {
    local pattern="$1"
    local mode="$2"
    local gate="$3"
    local reason="$4"
    local action="$5"
    local context_json="${6:-}"

    # Validate known patterns to keep metrics clean
    case "$pattern" in
        depth-ladder|safe-degrade|circle-risk-focus|autocommit-shadow|guardrail-lock|failure-strategy|iteration-budget|observability-first)
            ;;
        *)
            # Unknown pattern; skip logging to avoid polluting metrics
            return 0
            ;;
    esac

    local ts
    ts="$(date -u +"%Y-%m-%dT%H:%M:%SZ")"

    local run_kind="${AF_RUN_KIND:-unknown}"
    local iteration="${AF_RUN_ITERATION:-0}"
    local circle="${AF_CIRCLE:-unknown}"
    local depth="${AF_DEPTH_LEVEL:-0}"
    local framework="${AF_FRAMEWORK:-}"
    local scheduler="${AF_SCHEDULER:-}"
    local mutation="false"
    if [[ "$mode" == *"mutate"* ]] || [[ "$mode" == *"enforce"* ]] || [[ "$mode" == *"blocking"* ]]; then
        mutation="true"
    fi

    # Ensure .goalie directory exists
    mkdir -p "$PROJECT_ROOT/.goalie"

    # Base JSON fields
    printf "{\"ts\":\"%s\",\"run\":\"%s\",\"iteration\":%s," \
        "$ts" "$run_kind" "$iteration" >> "$PROJECT_ROOT/.goalie/pattern_metrics.jsonl"
    printf "\"circle\":\"%s\",\"depth\":%s," \
        "$circle" "$depth" >> "$PROJECT_ROOT/.goalie/pattern_metrics.jsonl"
    printf "\"pattern\":\"%s\",\"mode\":\"%s\",\"mutation\":%s,\"gate\":\"%s\"," \
        "$pattern" "$mode" "$mutation" "$gate" >> "$PROJECT_ROOT/.goalie/pattern_metrics.jsonl"

    # Final fields + optional context JSON (must be valid JSON value, typically an object)
    printf "\"framework\":\"%s\",\"scheduler\":\"%s\",\"reason\":\"%s\",\"action\":\"%s\"" \
        "$framework" "$scheduler" "$reason" "$action" >> "$PROJECT_ROOT/.goalie/pattern_metrics.jsonl"

    if [ -n "$context_json" ]; then
        printf ",\"context\":%s" "$context_json" >> "$PROJECT_ROOT/.goalie/pattern_metrics.jsonl"
    fi

    printf "}\n" >> "$PROJECT_ROOT/.goalie/pattern_metrics.jsonl"
}

show_help() {
    cat <<EOF
${BLUE}af - Agentic Flow Unified Command Interface${NC}

${GREEN}Status & Analysis:${NC}
  af status              Show comprehensive system status
  af metrics             Display metrics dashboard
  af analyze             Run doc_query analysis

${GREEN}Production Maturity & Observability:${NC}
  af retro-analysis      Run production maturity retrospective analysis
  af flow-metrics        Show flow & learning metrics (WSJF, BML throughput)
  af validate-success    Validate production success criteria
  af validate-dt         Validate Decision Transformer trajectories
  af dt-summary          Summarize DT readiness (strict mode)
  af dt-dataset-summary  Show DT dataset features & normalization summary
  af dt-dashboard        Visualize DT evaluation metrics over time
  af dt-ci-history       Analyze CI history for DT calibration guardrail
  af reward-presets     List DT reward presets & semantics

${GREEN}IRIS Agent Framework:${NC}
  af iris-health         Quick health check across all projects
  af iris-discover       Discover and instrument expert agents
  af iris-evaluate       Evaluate project health and expert performance
  af iris-patterns       Discover patterns across projects
  af iris-telemetry      Show telemetry health (AgentDB + Supabase)
  af iris-federated      Federated learning control plane
  af iris-config         Show IRIS configuration

${GREEN}Feedback Loop:${NC}
  af insight <text>      Capture retro insight
  af action <title>      Create tracked action item
  af quick-wins          Show Quick Wins progress
  af wsjf                Calculate WSJF priorities

${GREEN}Environment:${NC}
  af snapshot [name]     Create environment snapshot
  af restore [name]      Restore environment snapshot
  af baseline            Capture baseline metrics

${GREEN}Validation:${NC}
  af validate            Run governor validation
  af test                Run concurrent tests
  af governor            Check governor stats
  af governor-health     Validate governor + process tree + BML health

${GREEN}Learning:${NC}
  af hooks               Check hook discoverability
  af events              Show recent learning events
  af beam                Show BEAM dimensions
  af train-dt            Train Decision Transformer model from prepared dataset

${GREEN}Build-Measure-Learn:${NC}
  af cycle               Show current BML cycle status
  af commit              Create BML cycle commit
  af feedback            Analyze feedback loops
  af action              Create retro action item
  af suggest-team        Suggest circle teams for NOW items (read-only)
  af suggest-actions     Suggest actions from recent insights (read-only)
  af full-cycle [n]      Run n full BML + health passes (default 1)

${GREEN}Context Reduction:${NC}
  af board               Show Kanban board (NOW/NEXT/LATER)
  af blockers            List active blockers
  af cpu                 Check CPU and governor health

Examples:
  af status                    # Quick health check
  af insight "Reduce CPU load" # Capture retro insight
  af action "Fix IPMI"         # Create tracked action
  af snapshot baseline         # Save current state
  af board                     # Show work in progress

EOF
}

# Status command - comprehensive health check
cmd_status() {
    echo -e "${BLUE}=== Agentic Flow Status ===${NC}\n"

    # Git status
    echo -e "${GREEN}Git:${NC}"
    git --no-pager log --oneline -1
    echo ""

    # AgentDB status
    echo -e "${GREEN}AgentDB:${NC}"
    if [ -f "$PROJECT_ROOT/.agentdb/agentdb.sqlite" ]; then
        echo "  Tables: $(sqlite3 "$PROJECT_ROOT/.agentdb/agentdb.sqlite" "SELECT COUNT(*) FROM sqlite_master WHERE type='table';")"
        echo "  execution_contexts: $(sqlite3 "$PROJECT_ROOT/.agentdb/agentdb.sqlite" "SELECT COUNT(*) FROM execution_contexts;" 2>/dev/null || echo "0")"
        echo "  beam_dimensions: $(sqlite3 "$PROJECT_ROOT/.agentdb/agentdb.sqlite" "SELECT COUNT(*) FROM beam_dimensions;" 2>/dev/null || echo "0")"
    else
        echo "  ❌ AgentDB not found"
    fi
    echo ""

    # Goalie status
    echo -e "${GREEN}Goalie Tracking:${NC}"
    if [ -f "$PROJECT_ROOT/.goalie/KANBAN_BOARD.yaml" ]; then
        local now_count=$(grep -A 20 "NOW:" "$PROJECT_ROOT/.goalie/KANBAN_BOARD.yaml" | grep -e "- id:" | wc -l | tr -d ' ')
        local next_count=$(grep -A 20 "NEXT:" "$PROJECT_ROOT/.goalie/KANBAN_BOARD.yaml" | grep -e "- id:" | wc -l | tr -d ' ')
        local done_count=$(grep -A 100 "DONE:" "$PROJECT_ROOT/.goalie/KANBAN_BOARD.yaml" | grep -e "- id:" | wc -l | tr -d ' ')
        echo "  NOW: $now_count | NEXT: $next_count | DONE: $done_count"
    fi
    echo ""

    # CPU & Governor
    echo -e "${GREEN}System Health:${NC}"
    local load=$(uptime | awk -F'load averages:' '{print $2}' | awk '{print $1}')
    echo "  Load: $load"
    if [ -f "$PROJECT_ROOT/logs/governor_incidents.jsonl" ]; then
        local incidents=$(wc -l < "$PROJECT_ROOT/logs/governor_incidents.jsonl" | tr -d ' ')
        echo "  Governor incidents: $incidents"
    fi
    echo ""

    # Snapshots
    echo -e "${GREEN}Snapshots:${NC}"
    if [ -d "$PROJECT_ROOT/.snapshots" ]; then
        ls -1 "$PROJECT_ROOT/.snapshots" | head -5
    else
        echo "  (no snapshots)"
    fi
}

# Metrics dashboard
cmd_metrics() {
    if [ -f "$PROJECT_ROOT/.goalie/metrics_dashboard.md" ]; then
        cat "$PROJECT_ROOT/.goalie/metrics_dashboard.md"
    else
        echo -e "${YELLOW}Metrics dashboard not found. Run: $SCRIPT_DIR/baseline-metrics.sh${NC}"
    fi
}

# Doc query analysis
cmd_analyze() {
    local query="${1:-BLOCKER|retro|Quick Win}"
    python3 "$SCRIPT_DIR/doc_query.py" "$query"
}

# Capture insight
cmd_insight() {
    local text="$*"
    if [ -z "$text" ]; then
        echo "Usage: af insight <text>"
        exit 1
    fi

    local timestamp=$(date -u +%Y%m%d_%H%M%S)
    echo "{\"timestamp\": \"$timestamp\", \"type\": \"retro_insight\", \"text\": \"$text\"}" | \
        tee -a "$PROJECT_ROOT/.goalie/insights_log.jsonl"
    echo -e "${GREEN}✓ Insight captured${NC}"
}

# Create action item
cmd_action() {
    local title="$*"
    if [ -z "$title" ]; then
        echo "Usage: af action <title>"
        exit 1
    fi

    if [ -f "$SCRIPT_DIR/create_action_item.sh" ]; then
        bash "$SCRIPT_DIR/create_action_item.sh" "$title"
    else
        echo -e "${YELLOW}create_action_item.sh not found${NC}"
        # Fallback: append to CONSOLIDATED_ACTIONS.yaml
        echo "  - title: \"$title\"" >> "$PROJECT_ROOT/.goalie/CONSOLIDATED_ACTIONS.yaml"
        echo -e "${GREEN}✓ Action added to CONSOLIDATED_ACTIONS.yaml${NC}"
    fi
}

# Suggest circle teams for NOW items (read-only)
cmd_suggest_team() {
    echo -e "${BLUE}=== Suggested Circle Teams (NOW lane) ===${NC}\n"
    if [ -f "$SCRIPT_DIR/agentic/suggest_team.py" ]; then
        python3 "$SCRIPT_DIR/agentic/suggest_team.py" || \
            echo -e "${YELLOW}suggest_team.py failed${NC}"
    else
        echo -e "${YELLOW}suggest_team.py not found${NC}"
    fi
}

# Suggest actions from recent insights (read-only)
cmd_suggest_actions() {
    echo -e "${BLUE}=== Suggested Actions from Recent Insights ===${NC}\n"
    if [ -f "$SCRIPT_DIR/agentic/suggest_actions.py" ]; then
        python3 "$SCRIPT_DIR/agentic/suggest_actions.py" || \
            echo -e "${YELLOW}suggest_actions.py failed${NC}"
    else
        echo -e "${YELLOW}suggest_actions.py not found${NC}"
    fi
}

# Quick wins progress
cmd_quick_wins() {
    if [ -f "$SCRIPT_DIR/show_quick_wins_progress.sh" ]; then
        bash "$SCRIPT_DIR/show_quick_wins_progress.sh"
    else
        echo -e "${YELLOW}show_quick_wins_progress.sh not found${NC}"
        if [ -f "$PROJECT_ROOT/docs/QUICK_WINS.md" ]; then
            grep -E "^\- \[.\]" "$PROJECT_ROOT/docs/QUICK_WINS.md" | head -20
        fi
    fi
}

# WSJF calculation
cmd_wsjf() {
    if command -v npx &> /dev/null; then
        cd "$PROJECT_ROOT" && npx goalie@latest recalc-wsjf 2>&1 || echo -e "${YELLOW}goalie not available${NC}"
    else
        echo -e "${YELLOW}npx not found${NC}"
    fi
}

# Environment snapshot
cmd_snapshot() {
    local name="${1:-baseline}"
    bash "$SCRIPT_DIR/restore-environment.sh" --snapshot "$name"
}

# Environment restore
cmd_restore() {
    local name="${1:-baseline}"
    bash "$SCRIPT_DIR/restore-environment.sh" --snapshot "$name"
}

# Baseline metrics
cmd_baseline() {
    bash "$SCRIPT_DIR/baseline-metrics.sh" "$@"
}

# Governor validation
cmd_validate() {
    bash "$SCRIPT_DIR/validate-governor-integration.sh" "$@"
}

# Run tests
cmd_test() {
    if [ -f "$SCRIPT_DIR/run-concurrent-tests.sh" ]; then
        bash "$SCRIPT_DIR/run-concurrent-tests.sh"
    else
        cd "$PROJECT_ROOT" && npm test
    fi
}

# Governor stats
cmd_governor() {
    echo -e "${BLUE}=== Governor Stats ===${NC}\n"
    if [ -f "$PROJECT_ROOT/logs/governor_incidents.jsonl" ]; then
        local total=$(wc -l < "$PROJECT_ROOT/logs/governor_incidents.jsonl" | tr -d ' ')
        local recent=$(tail -10 "$PROJECT_ROOT/logs/governor_incidents.jsonl")
        echo "Total incidents: $total"
        echo ""
        echo "Recent (last 10):"
        echo "$recent" | jq -r '"\(.timestamp) - \(.reason)"' 2>/dev/null || echo "$recent"
    else
        echo "No incidents logged"
    fi
}

# Check hooks
cmd_hooks() {
    echo -e "${BLUE}=== Hook Discoverability ===${NC}\n"
    if [ -d "$PROJECT_ROOT/.agentdb/hooks" ]; then
        find "$PROJECT_ROOT/.agentdb/hooks" -type f
    else
        echo -e "${YELLOW}.agentdb/hooks not found${NC}"
    fi
}

# Learning events
cmd_events() {
    local count="${1:-20}"
    echo -e "${BLUE}=== Recent Learning Events ===${NC}\n"
    if [ -f "$PROJECT_ROOT/logs/learning/events.jsonl" ]; then
        tail -n "$count" "$PROJECT_ROOT/logs/learning/events.jsonl" | jq -r '"\(.timestamp) - \(.event)"' 2>/dev/null
    else
        echo -e "${YELLOW}logs/learning/events.jsonl not found${NC}"
    fi
}

# BEAM dimensions
cmd_beam() {
    echo -e "${BLUE}=== BEAM Dimensions ===${NC}\n"
    if [ -f "$PROJECT_ROOT/.agentdb/agentdb.sqlite" ]; then
        sqlite3 "$PROJECT_ROOT/.agentdb/agentdb.sqlite" \
            "SELECT * FROM beam_dimensions LIMIT 10;" 2>/dev/null || \
            echo "No BEAM dimensions found"
    else
        echo -e "${YELLOW}AgentDB not found${NC}"
    fi
}

# BML cycle status
cmd_cycle() {
    echo -e "${BLUE}=== Build-Measure-Learn Cycle ===${NC}\n"
    if [ -f "$PROJECT_ROOT/.goalie/cycle_log.jsonl" ]; then
        tail -5 "$PROJECT_ROOT/.goalie/cycle_log.jsonl" | jq -r 'select(.type == "BML-CYCLE") | "\(.id) - \(.status)"' 2>/dev/null
    else
        echo "No cycle log found"
    fi
}

# BML commit
cmd_commit() {
    local msg="${*:-BML cycle $(date +%Y%m%d_%H%M%S)}"
    cd "$PROJECT_ROOT"
    git add .goalie/ .agentdb/ logs/ metrics/ 2>/dev/null || true
    git commit -m "$msg" || echo -e "${YELLOW}Nothing to commit${NC}"
}

# Feedback analysis
cmd_feedback() {
    if [ -f "$SCRIPT_DIR/feedback-loop-analyzer.sh" ]; then
        bash "$SCRIPT_DIR/feedback-loop-analyzer.sh"
    else
        echo -e "${YELLOW}feedback-loop-analyzer.sh not found${NC}"
    fi
}

# Full BML + health cycle
cmd_full_cycle() {
    local iterations="${1:-1}"

    case "$iterations" in
        ''|*[!0-9]*)
            echo -e "${YELLOW}Invalid iteration count: $iterations (must be positive integer)${NC}"
            return 1
            ;;
    esac

    if [ "$iterations" -le 0 ]; then
        echo -e "${YELLOW}Iteration count must be > 0${NC}"
        return 1
    fi

    local i
    for i in $(seq 1 "$iterations"); do
        echo -e "${BLUE}=== Full BML + Health Cycle $i/$iterations ===${NC}\n"

        cmd_status
        echo ""
        cmd_board
        echo ""
        cmd_suggest_team
        echo ""
        cmd_metrics
        echo ""
        cmd_cycle
        echo ""
        cmd_governor_health
        echo ""

        if [ -f "$SCRIPT_DIR/doc_query.py" ]; then
            echo -e "${BLUE}=== Circle Roles Snapshot (doc_query) ===${NC}\n"
            python3 "$SCRIPT_DIR/doc_query.py" "Analyst|Assessor|Innovator|Intuitive|Seeker" --max-depth 6 || \
                echo -e "${YELLOW}doc_query.py failed${NC}"
        fi

        cmd_suggest_actions
        echo ""

        # IRIS Integration: Evaluate and discover patterns if enabled
        if [ "$AF_ENABLE_IRIS_METRICS" = "1" ]; then
            echo -e "${BLUE}=== IRIS Evaluation (iteration $i) ===${NC}\n"
            $AF_IRIS_CMD evaluate 2>/dev/null || echo -e "${YELLOW}IRIS evaluate skipped${NC}"
            capture_iris_metrics "evaluate" "--iteration" "$i"

            echo -e "${BLUE}=== IRIS Pattern Discovery (iteration $i) ===${NC}\n"
            $AF_IRIS_CMD patterns 2>/dev/null || echo -e "${YELLOW}IRIS patterns skipped${NC}"
            capture_iris_metrics "patterns" "--iteration" "$i"
            echo ""
        fi

        # Optional autocommit path behind test-first guardrails
        local do_autocommit="${AF_FULL_CYCLE_AUTOCOMMIT:-0}"
        if [ "$do_autocommit" = "1" ]; then
            echo -e "${BLUE}=== Autocommit Guardrails (iteration $i) ===${NC}\n"

            # Test-first guardrail (can be disabled with AF_FULL_CYCLE_TEST_FIRST=0)
            local run_tests="${AF_FULL_CYCLE_TEST_FIRST:-1}"
            if [ "$run_tests" = "1" ]; then
                echo -e "${BLUE}Running tests via af test...${NC}\n"
                cmd_test
                local test_status=$?
                if [ "$test_status" -ne 0 ]; then
                    echo -e "${RED}Tests failed (status=$test_status); skipping autocommit for this iteration.${NC}"
                    METRIC_SAFE_DEGRADE_TRIGGERS=$((METRIC_SAFE_DEGRADE_TRIGGERS + 1))
                    continue
                fi

                echo -e "${BLUE}Running governor validation via af validate...${NC}\n"
                cmd_validate
                local validate_status=$?
                if [ "$validate_status" -ne 0 ]; then
                    echo -e "${RED}Governor validation failed (status=$validate_status); skipping autocommit for this iteration.${NC}"
                    METRIC_SAFE_DEGRADE_TRIGGERS=$((METRIC_SAFE_DEGRADE_TRIGGERS + 1))
                    continue
                fi
            fi

            # Only autocommit if there are changes, and warn if there are unsafe ones
            cd "$PROJECT_ROOT"
            local changed
            changed=$(git status --porcelain 2>/dev/null || true)
            METRIC_AUTOCOMMIT_CANDIDATES=$(echo "$changed" | grep -v "^$" | wc -l | tr -d ' ')
            if [ -z "$changed" ]; then
                echo -e "${YELLOW}No changes detected; nothing to autocommit.${NC}"
            else
                local unsafe
                unsafe=$(echo "$changed" | awk '{print $2}' | grep -Ev '^(\.goalie/|\.agentdb/|logs/|metrics/)' || true)

                if [ -n "$unsafe" ]; then
                    echo -e "${YELLOW}Unsafe changes detected outside [.goalie, .agentdb, logs, metrics]; autocommit will include only safe paths via cmd_commit.${NC}"
                    echo "$unsafe" | sed 's/^/  - /'
                fi

                echo -e "${GREEN}Creating BML full-cycle auto-commit for safe paths (.goalie, .agentdb, logs, metrics).${NC}"
                cmd_commit "BML full-cycle auto-commit (iteration $i of $iterations)"

                # Optional code-level autocommit under additional guardrails and policy
                local allow_code="${AF_ALLOW_CODE_AUTOCOMMIT:-0}"
                if [ "$allow_code" = "1" ] && [ -f "$PROJECT_ROOT/.goalie/autocommit_policy.yaml" ]; then
                    echo -e "${BLUE}Evaluating code-level autocommit via code_guardrails...${NC}\n"

                    local changed_paths
                    changed_paths=$(echo "$changed" | awk '{print $2}')

                    local safe_code_files
                    safe_code_files=$(printf '%s\n' "$changed_paths" | \
                        python3 "$SCRIPT_DIR/agentic/code_guardrails.py" --filter-code 2>/dev/null || true)

                    if [ -n "$safe_code_files" ]; then
                        echo -e "${GREEN}Staging code files approved by guardrails:${NC}"
                        echo "$safe_code_files" | sed 's/^/  - /'

                        while IFS= read -r f; do
                            [ -n "$f" ] && git add "$f"
                        done <<< "$safe_code_files"

                        git commit -m "BML full-cycle code auto-commit (iteration $i of $iterations)" || \
                            echo -e "${YELLOW}No code changes to commit (code-level).${NC}"
                    else
                        echo -e "${YELLOW}No eligible code files for auto-commit after guardrails.${NC}"
                    fi
                fi
            fi
        fi

        # Retro Coach Integration (Per-Iteration)
        echo -e "${BLUE}=== Retro Coach Analysis (iteration $i) ===${NC}\n"
        # Assuming run_id is not easily available here without parsing args or generating one,
        # but we can pass a placeholder or try to reuse one if available.
        # cmd_full_cycle doesn't seem to generate a run_id itself, but governance.py does.
        # However, for now we'll just pass the iteration index.
        cmd_retro_coach_with_metrics "auto-cycle-$(date +%s)" "$i" || echo -e "${YELLOW}Retro Coach failed; continuing cycle.${NC}"

        if [ "$i" -lt "$iterations" ]; then
            echo -e "\n${GREEN}--- End of iteration $i ---${NC}\n"
        fi
    done
}

# Kanban board
cmd_board() {
    if [ -f "$PROJECT_ROOT/.goalie/KANBAN_BOARD.yaml" ]; then
        cat "$PROJECT_ROOT/.goalie/KANBAN_BOARD.yaml" | grep -A 50 "NOW:" | head -60
    else
        echo -e "${YELLOW}KANBAN_BOARD.yaml not found${NC}"
    fi
}

# Active blockers
cmd_blockers() {
    python3 "$SCRIPT_DIR/doc_query.py" "BLOCKER-[0-9]+" | head -50
}

# CPU check
cmd_cpu() {
    echo -e "${BLUE}=== CPU & Governor Health ===${NC}\n"
    uptime
    echo ""
    if [ -f "$PROJECT_ROOT/logs/governor_incidents.jsonl" ]; then
        echo "Governor incidents (last 24h): $(find "$PROJECT_ROOT/logs/governor_incidents.jsonl" -mtime -1 -exec wc -l {} \; 2>/dev/null || echo "0")"
    fi
}

# Governor validation + health suite
cmd_governor_health() {
    if [ "${AF_SKIP_GOVERNOR_HEALTH:-0}" = "1" ]; then
        echo -e "${YELLOW}[af] Skipping governor-health suite (AF_SKIP_GOVERNOR_HEALTH=1).${NC}"
        return 0
    fi

    local trace_enabled="0"
    if [ "${AF_TRACE_GOVERNOR_HEALTH:-0}" = "1" ]; then
        set -x
        trace_enabled="1"
    fi

    echo -e "${BLUE}=== Governor Validation & Health Suite ===${NC}\n"

    # 1) Run governor validation
    if [ -f "$SCRIPT_DIR/validate-governor-integration.sh" ]; then
        bash "$SCRIPT_DIR/validate-governor-integration.sh" "$@"
    else
        echo -e "${YELLOW}validate-governor-integration.sh not found${NC}"
    fi

    echo ""

    # 2) Capture a single process tree snapshot
    if [ -f "$SCRIPT_DIR/monitoring/process_tree_watch.js" ]; then
        echo -e "${GREEN}Process tree snapshot (process_tree_watch --once):${NC}"
        node "$SCRIPT_DIR/monitoring/process_tree_watch.js" --once || \
            echo -e "${YELLOW}process_tree_watch.js failed${NC}"
    fi

    echo ""

    # 3) Run BML health check
    if [ -f "$SCRIPT_DIR/agentic/health_check.py" ]; then
        echo -e "${GREEN}BML health check:${NC}"
        python3 "$SCRIPT_DIR/agentic/health_check.py" || \
            echo -e "${YELLOW}health_check.py failed${NC}"
    else
        echo -e "${YELLOW}health_check.py not found${NC}"
    fi

    if [ "$trace_enabled" = "1" ]; then
        { set +x; } 2>/dev/null
    fi
}

cmd_multi_pattern_coverage() {
    local json_mode=0
    local dirs_arg=""

    while [[ $# -gt 0 ]]; do
        case "$1" in
            --json)
                json_mode=1
                shift
                ;;
            --dirs)
                dirs_arg="${2:-}"
                shift 2
                ;;
            *)
                echo -e "${YELLOW}Ignoring unknown multi-pattern-coverage option: $1${NC}" >&2
                shift
                ;;
        esac
    done

    if [ "$json_mode" -ne 1 ]; then
        echo -e "${RED}multi-pattern-coverage currently supports only --json mode${NC}" >&2
        return 1
    fi

    if [ -z "$dirs_arg" ]; then
        # Default to current PROJECT_ROOT/.goalie for compatibility
        dirs_arg="${PROJECT_ROOT}/.goalie"
    fi

    IFS=',' read -r -a goalie_dirs <<< "$dirs_arg"

    AF_MULTI_GOALIE_DIRS="$dirs_arg" python3 - << 'PY'
import json
import os
import subprocess
import sys
from datetime import datetime

project_root = os.environ.get("PROJECT_ROOT", os.getcwd())

raw_dirs = os.environ.get("AF_MULTI_GOALIE_DIRS", "")
if not raw_dirs:
    print(json.dumps({"error": "AF_MULTI_GOALIE_DIRS not set"}))
    sys.exit(1)

goalie_dirs = [d.strip() for d in raw_dirs.split(',') if d.strip()]

if not goalie_dirs:
    print(json.dumps({"error": "No Goalie dirs provided"}))
    sys.exit(1)

per_env = []
all_patterns = {}

def run_pattern_coverage(goalie_dir: str):
    env = os.environ.copy()
    env["PROJECT_ROOT"] = project_root
    # Allow overriding Goalie dir via env for the called script
    env["AF_GOALIE_DIR"] = goalie_dir
    cmd = [os.path.join(project_root, "scripts", "af"), "pattern-coverage", "--json"]
    try:
        out = subprocess.check_output(cmd, env=env, stderr=subprocess.DEVNULL)
    except Exception as e:
        return {"error": f"failed to run pattern-coverage for {goalie_dir}: {e}"}
    try:
        return json.loads(out.decode("utf-8"))
    except Exception as e:
        return {"error": f"invalid JSON from pattern-coverage for {goalie_dir}: {e}"}

for gd in goalie_dirs:
    name = os.path.basename(os.path.normpath(gd)) or gd
    pc_json = run_pattern_coverage(gd)
    if "error" in pc_json:
        per_env.append({"name": name, "error": pc_json["error"]})
        continue

    per_env.append({
        "name": name,
        "coverage": pc_json.get("coverage", {}),
        "totals": pc_json.get("totals", {}),
        "patterns": pc_json.get("patterns", []),
    })

    for entry in pc_json.get("patterns", []):
        pname = entry.get("name")
        if not pname:
            continue
        agg = all_patterns.setdefault(pname, {"direct_events": 0, "inferred_events": 0})
        agg["direct_events"] += int(entry.get("direct_events", 0))
        agg["inferred_events"] += int(entry.get("inferred_events", 0))

# Compute global coverage across all envs
pattern_names = sorted(all_patterns.keys())
logged_patterns = 0
for pname in pattern_names:
    entry = all_patterns[pname]
    if entry["direct_events"] + entry["inferred_events"] > 0:
        logged_patterns += 1

total_patterns = len(pattern_names) or 8
coverage_pct = 0.0
if total_patterns > 0:
    coverage_pct = (float(logged_patterns) / float(total_patterns)) * 100.0

global_totals = {
    "direct_events": sum(v["direct_events"] for v in all_patterns.values()),
    "inferred_events": sum(v["inferred_events"] for v in all_patterns.values()),
}

payload = {
    "timestamp": datetime.utcnow().replace(microsecond=0).isoformat() + "Z",
    "environments": per_env,
    "global": {
        "coverage": {
            "unique_patterns_logged": logged_patterns,
            "total_patterns": total_patterns,
            "coverage_percentage": coverage_pct,
        },
        "totals": global_totals,
    },
}

print(json.dumps(payload))
PY
}


cmd_detect_observability_gaps() {
    echo -e "${BLUE}=== Observability Gap Detection ===${NC}\n"

    if [ -f "$SCRIPT_DIR/agentic/detect_observability_gaps.py" ]; then
        python3 "$SCRIPT_DIR/agentic/detect_observability_gaps.py" "$@"
    else
        echo -e "${RED}detect_observability_gaps.py not found at $SCRIPT_DIR/agentic/detect_observability_gaps.py${NC}"
        return 1
    fi
}

# Goalie Gaps Check (VSIX Validator)
cmd_goalie_gaps() {
    local vsix_path="${1:-}"
    if [ -z "$vsix_path" ]; then
        echo -e "${RED}Error: VSIX path required.${NC}"
        echo "Usage: af goalie-gaps <path-to-vsix>"
        return 1
    fi

    if [ ! -f "$vsix_path" ]; then
        echo -e "${RED}Error: VSIX file not found at $vsix_path${NC}"
        return 1
    fi

    echo -e "${BLUE}Validating VSIX: $vsix_path${NC}"

    local tmp_dir
    tmp_dir="$(mktemp -d)"
    trap 'rm -rf "$tmp_dir"' RETURN

    unzip -q "$vsix_path" -d "$tmp_dir"

    local ext_dir="$tmp_dir/extension"
    if [ ! -d "$ext_dir" ]; then
        echo -e "${RED}Error: Invalid VSIX structure (no extension/ folder)${NC}"
        return 1
    fi

    if [ ! -f "$ext_dir/scripts/gap-check.js" ]; then
        echo -e "${RED}Error: scripts/gap-check.js not found in VSIX${NC}"
        return 1
    fi

    echo "Running gap-check.js..."
    # Pass remaining arguments to the script
    (cd "$ext_dir" && node scripts/gap-check.js "${@:2}")
}

# Governance federation helpers (Retro Coach + Governance Agent)
cmd_retro_coach() {
    cd "$PROJECT_ROOT"
    if command -v npx &> /dev/null; then
        npx tsx tools/federation/retro_coach.ts --goalie-dir "$PROJECT_ROOT/.goalie" "$@"
    else
        echo -e "${YELLOW}npx not found; cannot run retro_coach.ts${NC}"
        return 1
    fi
}

cmd_retro_coach_with_metrics() {
    local run_id="${1:-}"
    local cycle_index="${2:-0}"
    local log_file="${3:-$PROJECT_ROOT/.goalie/metrics_log.jsonl}"

    local tmp_json
    tmp_json="$(mktemp)"

    # Run retro_coach in JSON mode
    if ! cmd_retro_coach --json > "$tmp_json"; then
        echo -e "${YELLOW}Retro Coach failed to generate JSON${NC}"
        rm -f "$tmp_json"
        return 1
    fi

    # Extract fields using jq
    local methods
    methods=$(jq -r '.methods[]? // empty' "$tmp_json" | sed 's/^/--retro-method /' | tr '\n' ' ')

    local patterns
    patterns=$(jq -r '.design_patterns[]? // empty' "$tmp_json" | sed 's/^/--retro-design-pattern /' | tr '\n' ' ')

    local prototypes
    prototypes=$(jq -r '.event_prototypes[]? // empty' "$tmp_json" | sed 's/^/--retro-event-prototype /' | tr '\n' ' ')

    local exit_code
    exit_code=$(jq -r '.exit_code // 0' "$tmp_json")

    local rca
    rca=$(jq -r '.rca_5_whys[]? // empty' "$tmp_json" | sed 's/^/--retro-rca-why /' | tr '\n' ' ')

    local merged
    merged=$(jq -r '.replenishment.merged // 0' "$tmp_json")

    local refined
    refined=$(jq -r '.replenishment.refined // 0' "$tmp_json")

    local error_tags
    error_tags=$(jq -r '.replenishment.error_tags[]? // empty' "$tmp_json" | sed 's/^/--retro-replenishment-error-tag /' | tr '\n' ' ')

    # Derive additional RCA hints from latest metrics entry (if present)
    local metrics_line
    local extra_args=""

    if [ -f "$log_file" ]; then
        metrics_line=$(tail -n 1 "$log_file")

        # dt_consecutive_failures_threshold_reached
        val=$(echo "$metrics_line" | jq -r '.metrics["rca.dt_consecutive_failures_threshold_reached"] // false')
        if [ "$val" = "true" ] || [ "$val" = "1" ]; then
            extra_args+=" --retro-method 5-whys --retro-method timeline-analysis"
            extra_args+=" --retro-design-pattern ml-training-guardrail --retro-design-pattern iteration-budget"
            extra_args+=" --retro-rca-why 'dt_dataset_build failed repeatedly; investigate ml-training-guardrail and iteration-budget.'"
        fi

        # prod_cycle_stagnation_threshold_reached
        val=$(echo "$metrics_line" | jq -r '.metrics["rca.prod_cycle_stagnation_threshold_reached"] // false')
        if [ "$val" = "true" ] || [ "$val" = "1" ]; then
            extra_args+=" --retro-method 5-whys --retro-method value-stream-mapping"
            extra_args+=" --retro-design-pattern governance-review --retro-design-pattern circle-risk-focus"
            extra_args+=" --retro-rca-why 'No progress detected across iterations; investigate governance-review and circle-risk-focus.'"
        fi

        # safe_degrade_overuse_flag
        val=$(echo "$metrics_line" | jq -r '.metrics["rca.safe_degrade_overuse_flag"] // false')
        if [ "$val" = "true" ] || [ "$val" = "1" ]; then
            extra_args+=" --retro-method 5-whys --retro-method fishbone"
            extra_args+=" --retro-design-pattern safe-degrade --retro-design-pattern iteration-budget"
            extra_args+=" --retro-rca-why 'Safe-degrade fired repeatedly; investigate whether degradation is masking root failures.'"
        fi

        # vsix_telemetry_gap_threshold_reached
        val=$(echo "$metrics_line" | jq -r '.metrics["rca.vsix_telemetry_gap_threshold_reached"] // false')
        if [ "$val" = "true" ] || [ "$val" = "1" ]; then
            extra_args+=" --retro-method 5-whys --retro-method fault-tree"
            extra_args+=" --retro-design-pattern observability-first --retro-design-pattern kanban-telemetry"
            extra_args+=" --retro-rca-why 'VSIX telemetry gaps detected; investigate observability-first and Kanban dashboard wiring.'"
        fi
    fi

    # Emit metrics
    python3 "$SCRIPT_DIR/emit_metrics.py" \
        --event-type retro_coach_run \
        --run-id "$run_id" \
        --cycle-index "$cycle_index" \
        --log-file "$log_file" \
        --retro-exit-code "$exit_code" \
        --retro-replenishment-merged "$merged" \
        --retro-replenishment-refined "$refined" \
        $methods $patterns $prototypes $rca $error_tags $extra_args

    # Print summary for user
    echo -e "${GREEN}Retro Coach Metrics Emitted.${NC}"
    jq -r '.insightsSummary.recentInsights[].text' "$tmp_json" | head -n 5 | sed 's/^/  - /'

    rm -f "$tmp_json"
}

cmd_governance_agent() {
    cd "$PROJECT_ROOT"
    if command -v npx &> /dev/null; then
        npx tsx tools/federation/governance_agent.ts --goalie-dir "$PROJECT_ROOT/.goalie" "$@"
    else
        echo -e "${YELLOW}npx not found; cannot run governance_agent.ts${NC}"
        return 1
    fi
}

cmd_governance_executor() {
    cd "$PROJECT_ROOT"
    if ! command -v npx &> /dev/null; then
        echo -e "${YELLOW}npx not found; cannot run governance_executor.ts${NC}"
        return 1
    fi

    mkdir -p "$PROJECT_ROOT/.goalie"

    local tmp_json
    tmp_json="$(mktemp "$PROJECT_ROOT/.goalie/governance_payload_XXXXXX.json")"

    if ! cmd_governance_agent --json > "$tmp_json"; then
        echo -e "${YELLOW}governance_agent failed; skipping governance executor${NC}"
        rm -f "$tmp_json"
        return 0
    fi

    local summary_out="$PROJECT_ROOT/.goalie/executor_summary.json"
    local error_log="$PROJECT_ROOT/.goalie/executor_errors.log"

    if [ "${AF_GOVERNANCE_EXECUTOR_DRY_RUN:-1}" = "1" ]; then
        npx tsx tools/federation/governance_executor.ts --dry-run < "$tmp_json" \
            > "$summary_out" 2>> "$error_log" || true
    else
        npx tsx tools/federation/governance_executor.ts < "$tmp_json" \
            > "$summary_out" 2>> "$error_log" || true
    fi

    rm -f "$tmp_json"
}




# Production maturity cycle (Delegated to Governance Middleware)
cmd_prod_cycle() {
    local middleware_script="$SCRIPT_DIR/policy/governance.py"

    if [ ! -f "$middleware_script" ]; then
        echo -e "${RED}Error: Governance middleware not found at $middleware_script${NC}"
        exit 1
    fi

    # Normalize shorthand positional iteration argument:
    #   af prod-cycle 100  ->  governance.py --iterations 100
    # while preserving all other flags for root-cause RCA/5W traceability.
    # Defaults to 100 iterations if not specified.
    local args=("$@")
    local normalized=()
    local environment=""

    # Extract optional --environment flag (without changing ordering of other flags)
    local remaining=()
    local i=0
    while [ $i -lt ${#args[@]} ]; do
        if [ "${args[$i]}" = "--environment" ]; then
            if [ $((i+1)) -lt ${#args[@]} ]; then
                environment="${args[$((i+1))]}"
                i=$((i+2))
                continue
            fi
        fi
        remaining+=("${args[$i]}")
        i=$((i+1))
    done

    if [ -n "$environment" ]; then
        normalized+=("--environment" "$environment")
    fi

    if [[ "${remaining[0]}" =~ ^[0-9]+$ ]]; then
        normalized+=("--iterations" "${remaining[0]}")
        # Append remaining arguments (skipping the first one)
        if [ ${#remaining[@]} -gt 1 ]; then
            normalized+=("${remaining[@]:1}")
        fi
    elif [ ${#remaining[@]} -eq 0 ]; then
        normalized+=("--iterations" "100")
    else
        normalized=("${remaining[@]}")
    fi

    # When forcing prod-cycle we already ran pre-flight checks; skip governor suite for speed.
    if [[ " ${normalized[*]} " == *" --force "* ]]; then
        export AF_SKIP_GOVERNOR_HEALTH="1"
    fi

    # Invoke Python Middleware with normalized arguments
    python3 "$middleware_script" "${normalized[@]}"
}

# Dynamic Policy Hook
if [ -f "$SCRIPT_DIR/policy/dynamic_autocommit.sh" ] && [ "$1" == "prod-cycle" ]; then
    source "$SCRIPT_DIR/policy/dynamic_autocommit.sh"
fi


log_prod_cycle_iteration_metrics() {
    local run_kind="${AF_RUN_KIND:-unknown}"
    if [ "$run_kind" != "prod-cycle" ]; then
        return 0
    fi

    local ts
    ts="$(date -u +"%Y-%m-%dT%H:%M:%SZ")"

    local iteration="${AF_RUN_ITERATION:-0}"
    local circle="${AF_CIRCLE:-unknown}"
    local depth="${AF_DEPTH_LEVEL:-0}"
    local mode="${AF_PROD_CYCLE_MODE:-advisory}"
    local run_id="${AF_RUN_ID:-unknown}"

    local requested="${AF_PC_REQUESTED_ITERATIONS:-0}"
    local max_iter="${AF_PC_MAX_ITER:-0}"
    local extensions="${AF_PC_EXTENSIONS_USED:-0}"
    local safe_degrade_triggers="${AF_PC_SAFE_DEGRADE_TRIGGERS:-0}"
    local recent_incidents="${AF_PC_RECENT_LOAD_INCIDENTS:-0}"
    local risk_score="${AF_PC_CURRENT_RISK_SCORE:-0}"

    local allow_code="${AF_ALLOW_CODE_AUTOCOMMIT:-0}"
    local full_autocommit="${AF_FULL_CYCLE_AUTOCOMMIT:-0}"
    local test_first="${AF_FULL_CYCLE_TEST_FIRST:-1}"
    local autocommit_runs="${AF_PC_AUTOCOMMIT_RUNS:-0}"

    local safe_degrade_reason="${AF_PC_SAFE_DEGRADE_REASON:-none}"

    local patt_depth_ladder="${AF_PROD_DEPTH_LADDER:-0}"
    local patt_safe_degrade="${AF_PROD_SAFE_DEGRADE:-0}"
    local patt_circle_risk_focus="${AF_PROD_CIRCLE_RISK_FOCUS:-0}"
    local patt_autocommit_shadow="${AF_PROD_AUTOCOMMIT_SHADOW:-0}"
    local patt_guardrail_lock="${AF_PROD_GUARDRAIL_LOCK:-0}"
    local patt_failure_strategy="${AF_PROD_FAILURE_STRATEGY:-0}"
    local patt_iteration_budget="${AF_PROD_ITERATION_BUDGET:-0}"
    local patt_observability_first="${AF_PROD_OBSERVABILITY_FIRST:-0}"

    local safe_degrade_actions="${AF_PC_SAFE_DEGRADE_ACTIONS:-[]}"
    local safe_degrade_recovery_raw="${AF_PC_SAFE_DEGRADE_RECOVERY_CYCLES:-0}"
    local safe_degrade_recovery="$safe_degrade_recovery_raw"
    if [[ "$safe_degrade_recovery_raw" =~ ^\[ ]]; then
      safe_degrade_recovery="0"
    fi

    local circle_risk_owner="${AF_PC_CIRCLE_RISK_FOCUS_TOP_OWNER:-none}"
    local circle_risk_extra="${AF_PC_CIRCLE_RISK_FOCUS_EXTRA_ITERATIONS:-0}"
    local circle_risk_reduction="${AF_PC_CIRCLE_RISK_FOCUS_ROAM_REDUCTION:-0}"

    local shadow_override="${AF_PC_AUTOCOMMIT_SHADOW_MANUAL_OVERRIDE:-0}"

    local guardrail_enforced="${AF_PC_GUARDRAIL_LOCK_ENFORCED:-0}"
    local guardrail_health="${AF_PC_GUARDRAIL_LOCK_HEALTH_STATE:-unknown}"
    local guardrail_requests="${AF_PC_GUARDRAIL_LOCK_USER_REQUESTS:-0}"

    local fail_strat_mode="${AF_PC_FAILURE_STRATEGY_MODE:-none}"
    local fail_strat_abort="${AF_PC_FAILURE_STRATEGY_ABORT_AT:-0}"
    local fail_strat_reason="${AF_PC_FAILURE_STRATEGY_DEGRADE_REASON:-none}"

    local budget_enforced="${AF_PC_ITERATION_BUDGET_ENFORCED:-0}"

    local obs_written="${AF_PC_OBSERVABILITY_METRICS_WRITTEN:-0}"
    local obs_missing="${AF_PC_OBSERVABILITY_MISSING_SIGNALS:-0}"
    local obs_suggest="${AF_PC_OBSERVABILITY_SUGGESTION_MADE:-0}"

    mkdir -p "$PROJECT_ROOT/.goalie"
    local out="$PROJECT_ROOT/.goalie/metrics_log.jsonl"

    # Use emit_metrics.py for strictly typed, schema-compliant logging
    # Calculates budget metrics: remaining = max - current, consumed = current
    local budget_remaining=$((max_iter - iteration))
    if [ "$budget_remaining" -lt 0 ]; then budget_remaining=0; fi

    python3 "$SCRIPT_DIR/emit_metrics.py" \
        --event-type "state" \
        --run-id "$run_id" \
        --cycle-index "$iteration" \
        --circle "$circle" \
        --depth "$depth" \
        --safe-degrade-triggers "$safe_degrade_triggers" \
        --safe-degrade-actions "$safe_degrade_actions" \
        --safe-degrade-recovery-cycles "$safe_degrade_recovery" \
        --circle-risk-focus-top-owner "$circle_risk_owner" \
        --circle-risk-focus-extra-iterations "$circle_risk_extra" \
        --circle-risk-focus-roam-reduction "$circle_risk_reduction" \
        --autocommit-shadow-manual-override "$shadow_override" \
        --guardrail-lock-enforced "$guardrail_enforced" \
        --guardrail-lock-health-state "$guardrail_health" \
        --guardrail-lock-user-requests "$guardrail_requests" \
        --failure-strategy-mode "$fail_strat_mode" \
        --failure-strategy-abort-iteration-at "$fail_strat_abort" \
        --failure-strategy-degrade-reason "$fail_strat_reason" \
        --iteration-budget-requested "$requested" \
        --iteration-budget-enforced "$budget_enforced" \
        --iteration-budget-autocommit-runs "$autocommit_runs" \
        --observability-first-metrics-written "$obs_written" \
        --observability-first-missing-signals "$obs_missing" \
        --observability-first-suggestion-made "$obs_suggest" \
        --autocommit-cycles "$autocommit_runs" \
        --budget-remaining "$budget_remaining" \
        --budget-consumed "$iteration" \
        --risk-score "$risk_score" \
        --recent-incidents "$recent_incidents" \
        --average-score "$risk_score" \
        --risk-distribution "${AF_PC_RISK_DISTRIBUTION:-{}}" \
        --log-file "$out" || echo "${YELLOW}Warning: Failed to emit metrics via emit_metrics.py${NC}"
}

# Main dispatch
if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
    case "${1:-help}" in
        status) cmd_status ;;
        metrics) cmd_metrics ;;
        analyze) shift; cmd_analyze "$@" ;;
        insight) shift; cmd_insight "$@" ;;
        action) shift; cmd_action "$@" ;;
        suggest-team) shift; cmd_suggest_team "$@" ;;
        suggest-actions) shift; cmd_suggest_actions "$@" ;;
        quick-wins) cmd_quick_wins ;;
        wsjf) cmd_wsjf ;;
        snapshot) shift; cmd_snapshot "$@" ;;
        restore) shift; cmd_restore "$@" ;;
        baseline) shift; cmd_baseline "$@" ;;
        validate) shift; cmd_validate "$@" ;;
        test) cmd_test ;;
        governor) cmd_governor ;;
        governor-health) shift; cmd_governor_health "$@" ;;
        hooks) cmd_hooks ;;
        events) shift; cmd_events "$@" ;;
        beam) cmd_beam ;;
        full-cycle) shift; cmd_full_cycle "${1:-1}" ;;
        prod-cycle) shift; cmd_prod_cycle "$@" ;;
        cycle) cmd_cycle ;;
        commit) shift; cmd_commit "$@" ;;
        feedback) cmd_feedback ;;
        board) cmd_board ;;
        blockers) cmd_blockers ;;
        cpu) cmd_cpu ;;
        goalie-gaps) shift; cmd_goalie_gaps "$@" ;;
        pattern-coverage) shift; cmd_pattern_coverage "$@" ;;
        multi-pattern-coverage) shift; cmd_multi_pattern_coverage "$@" ;;
        detect-observability-gaps) shift; cmd_detect_observability_gaps "$@" ;;
        sample-workloads) shift; cmd_sample_workloads "$@" ;;
        retro-coach) shift; cmd_retro_coach "$@" ;;
        governance-agent) shift; cmd_governance_agent "$@" ;;
        dt-e2e-check)
            shift
            if [ -f "$SCRIPT_DIR/analysis/dt_e2e_check.py" ]; then
                python3 "$SCRIPT_DIR/analysis/dt_e2e_check.py" "$@"
            else
                echo -e "${YELLOW}dt_e2e_check.py not found at $SCRIPT_DIR/analysis${NC}"
                exit 1
            fi
            ;;
        retro-analysis)
            shift
            if [ -x "$SCRIPT_DIR/analysis/retrospective_analysis.py" ]; then
                python3 "$SCRIPT_DIR/analysis/retrospective_analysis.py" "$@"
            else
                echo -e "${YELLOW}retrospective_analysis.py not found or not executable${NC}"
                exit 1
            fi
            ;;
        flow-metrics)
            shift
            if [ -x "$SCRIPT_DIR/analysis/flow_metrics.py" ]; then
                python3 "$SCRIPT_DIR/analysis/flow_metrics.py" "$@"
            else
                echo -e "${YELLOW}flow_metrics.py not found or not executable${NC}"
                exit 1
            fi
            ;;
        validate-success)
            shift
            if [ -x "$SCRIPT_DIR/analysis/validate_success_criteria.sh" ]; then
                bash "$SCRIPT_DIR/analysis/validate_success_criteria.sh" "$@"
            else
                echo -e "${YELLOW}validate_success_criteria.sh not found or not executable${NC}"
                exit 1
            fi
            ;;
        validate-dt)
            shift
            if [ -x "$SCRIPT_DIR/analysis/validate_dt_trajectories.py" ]; then
                python3 "$SCRIPT_DIR/analysis/validate_dt_trajectories.py" "$@"
            else
                echo -e "${YELLOW}validate_dt_trajectories.py not found or not executable${NC}"
                exit 1
            fi
            ;;
        dt-summary)
            shift
            if [ -x "$SCRIPT_DIR/analysis/validate_dt_trajectories.py" ]; then
                # Run validator in strict JSON mode and pretty-print a concise summary.
                raw_json=$(python3 "$SCRIPT_DIR/analysis/validate_dt_trajectories.py" --json --strict "$@")
                status=$?

                if [ -z "$raw_json" ]; then
                    echo -e "${YELLOW}[dt-summary] No DT summary produced (empty output)${NC}"
                    exit $status
                fi

                python3 - "$raw_json" << 'PYEOF'
import json
import sys

def main() -> int:
    if len(sys.argv) < 2:
        print("[dt-summary] missing JSON summary", file=sys.stderr)
        return 1
    raw = sys.argv[1]
    try:
        summary = json.loads(raw)
    except json.JSONDecodeError as exc:
        print(f"[dt-summary] failed to parse JSON summary: {exc}", file=sys.stderr)
        return 1

    strict = summary.get("strict_status", {})
    readiness = summary.get("readiness", {})
    episode_stats = summary.get("episode_stats", {})
    rewards = summary.get("rewards", {})

    malformed_fraction = strict.get("malformed_fraction", 0.0)
    violations = strict.get("violations", []) or []
    tolerance = strict.get("tolerance", 0.0)

    total_episodes = episode_stats.get("total_episodes", 0)
    reward_count = rewards.get("count", 0)

    warnings = readiness.get("warnings", []) or []
    infos = readiness.get("info", []) or []

    print("DT Summary (strict mode):")
    print(f"  Episodes: {total_episodes}")
    print(f"  Rewards:  {reward_count}")
    print("  Malformed rewards:")
    print(f"    fraction: {malformed_fraction:.3f} (tolerance {tolerance:.3f})")

    if violations:
        print("  Strict violations:")
        for v in violations:
            print(f"    - {v}")
    else:
        print("  Strict violations: none")

    if warnings:
        print("  Readiness warnings:")
        for w in warnings:
            print(f"    - {w}")
    else:
        print("  Readiness warnings: none")

    if infos:
        print("  Readiness info:")
        for i in infos:
            print(f"    - {i}")

    return 0

if __name__ == "__main__":
    raise SystemExit(main())
PYEOF

                exit $status
            else
                echo -e "${YELLOW}validate_dt_trajectories.py not found or not executable${NC}"
                exit 1
            fi
            ;;
	    dt-dataset-summary)
	        shift
	        if [ -f "$SCRIPT_DIR/analysis/prepare_dt_dataset.py" ]; then
	            python3 "$SCRIPT_DIR/analysis/prepare_dt_dataset.py" --summary-only "$@"
	        else
	            echo -e "${YELLOW}prepare_dt_dataset.py not found${NC}"
	            exit 1
	        fi
	        ;;
	    dt-dashboard)
	        shift
	        if [ -f "$SCRIPT_DIR/analysis/dt_evaluation_dashboard.py" ]; then
	            python3 "$SCRIPT_DIR/analysis/dt_evaluation_dashboard.py" "$@"
	        else
	            echo -e "${YELLOW}dt_evaluation_dashboard.py not found${NC}"
	            exit 1
	        fi
	        ;;
		    dt-ci-history)
		        shift
		        if [ -f "$SCRIPT_DIR/analysis/analyze_dt_ci_history.py" ]; then
		            python3 "$SCRIPT_DIR/analysis/analyze_dt_ci_history.py" "$@"
		        else
		            echo -e "${YELLOW}analyze_dt_ci_history.py not found at $SCRIPT_DIR/analysis${NC}"
		            exit 1
		        fi
		        ;;

	    dt-suggest-thresholds)
	        shift
	        if [ -f "$SCRIPT_DIR/analysis/suggest_dt_thresholds.py" ]; then
	            python3 "$SCRIPT_DIR/analysis/suggest_dt_thresholds.py" "$@"
	        else
	            echo -e "${YELLOW}suggest_dt_thresholds.py not found at $SCRIPT_DIR/analysis${NC}"
	            exit 1
	        fi
	        ;;
	    enforce-dt-gates)
	        shift
	        if [ -f "$SCRIPT_DIR/analysis/enforce_dt_quality_gates.py" ]; then
	            python3 "$SCRIPT_DIR/analysis/enforce_dt_quality_gates.py" "$@"
	        else
	            echo -e "${YELLOW}enforce_dt_quality_gates.py not found at $SCRIPT_DIR/analysis${NC}"
	            exit 1
	        fi
	        ;;
            publish-dt-gates-summary)
                shift
                if [ -f "$SCRIPT_DIR/analysis/publish_dt_gates_summary.py" ]; then
                    python3 "$SCRIPT_DIR/analysis/publish_dt_gates_summary.py" "$@"
                else
                    echo -e "${YELLOW}publish_dt_gates_summary.py not found at $SCRIPT_DIR/analysis${NC}"
                    exit 1
                fi
                ;;

		    reward-presets)
		        shift
		        if [ -f "$SCRIPT_DIR/analysis/list_reward_presets.py" ]; then
		            python3 "$SCRIPT_DIR/analysis/list_reward_presets.py" "$@"
		        else
		            echo -e "${YELLOW}list_reward_presets.py not found at $SCRIPT_DIR/analysis${NC}"
		            exit 1
		        fi
		        ;;

		    compare-presets)
		        shift
		        if [ -f "$SCRIPT_DIR/analysis/compare_presets.py" ]; then
		            python3 "$SCRIPT_DIR/analysis/compare_presets.py" "$@"
		        else
		            echo -e "${YELLOW}compare_presets.py not found at $SCRIPT_DIR/analysis${NC}"
		            exit 1
		        fi
		        ;;

        validate-dt-model)
            shift
            if [ -f "$SCRIPT_DIR/analysis/evaluate_dt_model.py" ]; then
                python3 "$SCRIPT_DIR/analysis/evaluate_dt_model.py" --validate-only "$@"
            else
                echo -e "${YELLOW}evaluate_dt_model.py not found${NC}"
                exit 1
            fi
            ;;

        evaluate-dt)
            shift
            if [ -f "$SCRIPT_DIR/analysis/evaluate_dt_model.py" ]; then
                python3 "$SCRIPT_DIR/analysis/evaluate_dt_model.py" "$@"
            else
                echo -e "${YELLOW}evaluate_dt_model.py not found${NC}"
                exit 1
            fi
            ;;

	    train-dt)
	        shift
	        if [ -f "$SCRIPT_DIR/analysis/train_dt_model.py" ]; then
	            python3 "$SCRIPT_DIR/analysis/train_dt_model.py" "$@"
	        else
	            echo -e "${YELLOW}train_dt_model.py not found${NC}"
	            exit 1
	        fi
	        ;;

	    # IRIS Agent Framework Commands
	    iris-health)
	        $AF_IRIS_CMD health
	        capture_iris_metrics "health"
	        ;;

	    iris-discover)
	        $AF_IRIS_CMD discover
	        capture_iris_metrics "discover"
	        ;;

	    iris-evaluate)
	        shift
	        $AF_IRIS_CMD evaluate "$@"
	        capture_iris_metrics "evaluate" "$@"
	        ;;

	    iris-patterns)
	        $AF_IRIS_CMD patterns
	        capture_iris_metrics "patterns"
	        ;;

	    iris-telemetry)
	        shift
	        $AF_IRIS_CMD telemetry "$@"
	        capture_iris_metrics "telemetry" "$@"
	        ;;

	    iris-federated)
	        shift
	        $AF_IRIS_CMD federated "$@"
	        capture_iris_metrics "federated" "$@"
	        ;;

	    iris-config)
	        $AF_IRIS_CMD config show
	        ;;


        help|--help|-h) show_help ;;
        *)
            echo -e "${RED}Unknown command: $1${NC}"
            echo "Run 'af help' for usage"
            exit 1
            ;;
    esac
fi
