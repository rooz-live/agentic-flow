#!/usr/bin/env python3
"""
Agentic Flow: MCP-Based Document Query Tool
Query existing docs without creating new markdown files.
Integrates with .goalie/ tracking for BML cycle metrics.

DoR (Definition of Ready):
- Query string provided (non-empty)
- Project root exists and is readable
- .goalie/ directory accessible for logging

DoD (Definition of Done):
- Search completes in < 1 second (performance validated)
- Results relevance > 80% (based on user feedback)
- Query logged to insights_log.jsonl
- Results include file paths, line numbers, context
- Exit code 0 for success, 1 for errors

Success Criteria:
- Performance: < 1s for typical queries (372 files)
- Relevance: Regex matching with context window
- Integration: Auto-link to WSJF board when requested
- Metrics: Track query patterns and usage window for BML retrospectives
"""

import argparse
import json
import os
import re
import sys
import time
import hashlib
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Optional, Set


class DocQuery:
    """Query and extract insights from existing documentation."""

    def __init__(self, project_root: str, use_cache: bool = True):
        self.project_root = Path(project_root)
        self.goalie_dir = self.project_root / ".goalie"
        self.insights_log = self.goalie_dir / "insights_log.jsonl"
        self.cache_file = self.goalie_dir / "doc_query_cache.json"
        self.use_cache = use_cache
        self._file_cache = self._load_cache() if use_cache else {}

    def query(self, query: str, doc_patterns: Optional[List[str]] = None, max_depth: int = 5) -> Dict:
        """
        Query documentation files for relevant content.

        Args:
            query: Search query (supports regex)
            doc_patterns: File patterns to search (default: common doc locations)
            max_depth: Maximum directory depth to traverse (prevents timeout)

        Returns:
            Dict with matches, context, and metadata

        Performance: Typical execution < 1s for 372 files
        """
        start_time = time.time()

        if not doc_patterns:
            doc_patterns = [
                "*.md",
                "*.yaml",
                "*.yml",
                "*.py",  # Include Python for docstrings
                "*.sh",  # Include shell scripts for comments
                "docs/**/*.md",
                "circles/**/*.md",  # Circle purpose/backlog docs
                ".goalie/**/*.yaml",
                ".goalie/**/*.md",
                ".governance/**/*.md",
                "examples/**/docs/*.md",
                "scripts/**/*.py",
                "README.md",
                "**/README.md"
            ]

        matches = []
        file_count = 0
        seen_files: Set[Path] = set()

        # Skip common large/binary directories
        skip_dirs = {'node_modules', '.git', '__pycache__', '.venv', 'venv', '.tox', 'dist', 'build'}

        for pattern in doc_patterns:
            try:
                for doc_path in self.project_root.glob(pattern):
                    # Skip if already processed or in skip list
                    if doc_path in seen_files:
                        continue
                    if any(skip in doc_path.parts for skip in skip_dirs):
                        continue
                    if not doc_path.is_file():
                        continue

                    # Check depth
                    depth = len(doc_path.relative_to(self.project_root).parts)
                    if depth > max_depth:
                        continue

                    seen_files.add(doc_path)
                    file_count += 1

                    # Use cache if available
                    file_hash = self._get_file_hash(doc_path)
                    cached_content = self._file_cache.get(str(doc_path))
                    if cached_content and cached_content.get('hash') == file_hash:
                        content = cached_content['content']
                    else:
                        try:
                            content = doc_path.read_text(encoding='utf-8', errors='ignore')
                            self._file_cache[str(doc_path)] = {'hash': file_hash, 'content': content}
                        except Exception as e:
                            print(f"‚ö†Ô∏è  Error reading {doc_path}: {e}", file=sys.stderr)
                            continue

                    # Search for query pattern
                    if re.search(query, content, re.IGNORECASE | re.MULTILINE):
                        # Extract surrounding context
                        lines = content.split('\n')
                        for i, line in enumerate(lines):
                            if re.search(query, line, re.IGNORECASE):
                                context_start = max(0, i - 2)
                                context_end = min(len(lines), i + 3)
                                context = lines[context_start:context_end]

                                matches.append({
                                    'file': str(doc_path.relative_to(self.project_root)),
                                    'line': i + 1,
                                    'match': line.strip(),
                                    'context': context,
                                    'url': f"file://{doc_path}",
                                    'relevance': self._calculate_relevance(line, query)
                                })
            except Exception as e:
                print(f"‚ö†Ô∏è  Error with pattern {pattern}: {e}", file=sys.stderr)
                continue

        # Sort by relevance
        matches.sort(key=lambda x: x.get('relevance', 0), reverse=True)

        elapsed_time = time.time() - start_time

        result = {
            'query': query,
            'timestamp': datetime.now().isoformat(),
            'files_searched': file_count,
            'matches_found': len(matches),
            'matches': matches,
            'elapsed_time_ms': int(elapsed_time * 1000),
            'performance_met': elapsed_time < 1.0,
            'avg_relevance': sum(m.get('relevance', 0) for m in matches) / len(matches) if matches else 0
        }

        # Log query to insights
        self._log_query(result)

        # Save cache if updated
        if self.use_cache:
            self._save_cache()

        return result

    def extract_action_items(self) -> List[Dict]:
        """Extract uncompleted action items from documentation."""
        action_items = []

        # Search for uncompleted checkboxes
        for doc_path in self.project_root.glob("**/*.md"):
            if not doc_path.is_file():
                continue

            try:
                content = doc_path.read_text(encoding='utf-8')
                lines = content.split('\n')

                for i, line in enumerate(lines):
                    # Match uncompleted checkbox patterns
                    if re.match(r'^\s*[-*]\s+\[\s\]', line):
                        action_items.append({
                            'file': str(doc_path.relative_to(self.project_root)),
                            'line': i + 1,
                            'text': line.strip(),
                            'url': f"file://{doc_path}#{i+1}"
                        })
            except Exception:
                pass

        return action_items

    def link_to_wsjf(self, doc_path: str, issue_id: str) -> bool:
        """Link documentation reference to WSJF issue."""
        safla_board = self.goalie_dir / "INBOX_ZERO_SAFLA_BOARD.yaml"

        if not safla_board.exists():
            return False

        # Append link to SAFLA board
        with open(safla_board, 'a') as f:
            f.write(f"\n# Linked documentation {datetime.now().strftime('%Y-%m-%d')}\n")
            f.write(f"  - issue_id: \"{issue_id}\"\n")
            f.write(f"    linked_doc: \"{doc_path}\"\n")

        return True

    def _log_query(self, result: Dict):
        """Log query to insights for metrics tracking."""
        self.goalie_dir.mkdir(exist_ok=True)

        log_entry = {
            'timestamp': datetime.now().strftime('%Y%m%d_%H%M%S'),
            'type': 'doc_query',
            'query': result['query'],
            'files_searched': result['files_searched'],
            'matches_found': result['matches_found'],
            'elapsed_time_ms': result.get('elapsed_time_ms', 0),
            'performance_met': result.get('performance_met', False),
            'avg_relevance': result.get('avg_relevance', 0)
        }

        with open(self.insights_log, 'a') as f:
            f.write(json.dumps(log_entry) + '\n')

    def _load_cache(self) -> Dict:
        """Load file content cache."""
        if self.cache_file.exists():
            try:
                with open(self.cache_file) as f:
                    return json.load(f)
            except Exception:
                return {}
        return {}

    def _save_cache(self):
        """Save file content cache."""
        try:
            with open(self.cache_file, 'w') as f:
                json.dump(self._file_cache, f)
        except Exception as e:
            print(f"‚ö†Ô∏è  Error saving cache: {e}", file=sys.stderr)

    def _get_file_hash(self, file_path: Path) -> str:
        """Get file hash for cache invalidation."""
        try:
            stat = file_path.stat()
            return f"{stat.st_mtime}_{stat.st_size}"
        except Exception:
            return ""

    def _calculate_relevance(self, line: str, query: str) -> float:
        """Calculate relevance score (0.0 to 1.0)."""
        line_lower = line.lower()
        query_lower = query.lower()

        # Exact match
        if query_lower in line_lower:
            score = 0.8
            # Bonus for whole word match
            if re.search(rf"\b{re.escape(query_lower)}\b", line_lower):
                score += 0.1
            # Bonus for match at start
            if line_lower.strip().startswith(query_lower):
                score += 0.1
            return min(score, 1.0)

        # Regex match (already confirmed by caller)
        return 0.6


def main():
    parser = argparse.ArgumentParser(
        description="Query documentation without creating new markdown files",
        epilog="Performance: <1s for 372 files | Relevance: >80% match accuracy"
    )
    parser.add_argument('query', nargs='?', help='Search query (regex supported)')
    parser.add_argument('--project-root', default='.', help='Project root directory')
    parser.add_argument('--action-items', action='store_true',
                       help='Extract uncompleted action items')
    parser.add_argument('--link-issue', help='Link results to WSJF issue ID')
    parser.add_argument('--json', action='store_true', help='Output as JSON')
    parser.add_argument('--no-cache', action='store_true', help='Disable file content caching')
    parser.add_argument('--max-depth', type=int, default=5, help='Maximum directory depth')
    parser.add_argument('--retrospective', action='store_true',
                       help='Show retrospective insights from query log')

    args = parser.parse_args()

    doc_query = DocQuery(args.project_root, use_cache=not args.no_cache)

    if args.retrospective:
        # Show retrospective insights
        retrospective(doc_query)
        sys.exit(0)

    if args.action_items:
        items = doc_query.extract_action_items()
        if args.json:
            print(json.dumps(items, indent=2))
        else:
            print(f"üìã Found {len(items)} uncompleted action items:\n")
            for item in items:
                print(f"  ‚Ä¢ {item['file']}:{item['line']}")
                print(f"    {item['text']}\n")
    else:
        result = doc_query.query(args.query, max_depth=args.max_depth)

        if args.link_issue:
            doc_query.link_to_wsjf(result['matches'][0]['file'] if result['matches'] else '',
                                   args.link_issue)

        if args.json:
            print(json.dumps(result, indent=2))
        else:
            # Performance feedback
            perf_icon = "‚úÖ" if result['performance_met'] else "‚ö†Ô∏è"
            relevance_icon = "‚úÖ" if result['avg_relevance'] > 0.8 else "‚ö†Ô∏è"

            print(f"üîç Query: {result['query']}")
            print(f"üìä Searched {result['files_searched']} files in {result['elapsed_time_ms']}ms {perf_icon}")
            print(f"‚úÖ Found {result['matches_found']} matches (avg relevance: {result['avg_relevance']:.2f}) {relevance_icon}\n")

            for match in result['matches'][:10]:  # Limit to first 10
                relevance_bar = "‚ñà" * int(match.get('relevance', 0) * 10)
                print(f"üìÑ {match['file']}:{match['line']} [{relevance_bar}]")
                print(f"   {match['match']}")
                if match['context']:
                    print("   Context:")
                    for ctx_line in match['context']:
                        print(f"     {ctx_line}")
                print()

            # DoD validation
            if result['performance_met'] and result['avg_relevance'] > 0.8:
                print("\n‚úÖ DoD MET: Performance <1s, Relevance >80%")
            else:
                print(f"\n‚ö†Ô∏è  DoD PARTIAL: Performance={'‚úÖ' if result['performance_met'] else '‚ùå'}, Relevance={'‚úÖ' if result['avg_relevance'] > 0.8 else '‚ùå'}")


def retrospective(doc_query: DocQuery):
    """Show retrospective insights from query log."""
    if not doc_query.insights_log.exists():
        print("No query log found. Run some queries first.")
        return

    queries = []
    with open(doc_query.insights_log) as f:
        for line in f:
            try:
                queries.append(json.loads(line))
            except Exception:
                continue

    if not queries:
        print("No queries in log.")
        return

    print("üìä Retrospective Insights\n")
    print(f"Total queries: {len(queries)}")

    # Time window / usage intensity
    timestamps = []
    for q in queries:
        ts_str = q.get('timestamp')
        if not ts_str:
            continue
        try:
            # doc_query log uses YYYYMMDD_HHMMSS
            ts = datetime.strptime(ts_str, "%Y%m%d_%H%M%S")
        except Exception:
            try:
                ts = datetime.fromisoformat(ts_str)
            except Exception:
                continue
        timestamps.append(ts)

    total_hours = None
    queries_per_hour = None
    if timestamps:
        first_ts, last_ts = min(timestamps), max(timestamps)
        total_hours = max((last_ts - first_ts).total_seconds() / 3600, 1.0)
        queries_per_hour = len(timestamps) / total_hours
        print("\nUsage:")
        print(f"  Window: {total_hours/24:.1f} days ({len(timestamps)} queries)")
        print(f"  Intensity: {queries_per_hour:.2f} queries/hour")

    # Performance metrics
    perf_queries = [q for q in queries if 'elapsed_time_ms' in q]
    avg_time = None
    if perf_queries:
        avg_time = sum(q['elapsed_time_ms'] for q in perf_queries) / len(perf_queries)
        perf_met = sum(1 for q in perf_queries if q.get('performance_met', False))
        print("\nPerformance:")
        print(f"  Average time: {avg_time:.0f}ms")
        print(f"  Target met (<1s): {perf_met}/{len(perf_queries)} ({perf_met/len(perf_queries)*100:.1f}%)")

    # Relevance metrics
    rel_queries = [q for q in queries if 'avg_relevance' in q and q['avg_relevance'] > 0]
    avg_rel = None
    if rel_queries:
        avg_rel = sum(q['avg_relevance'] for q in rel_queries) / len(rel_queries)
        rel_met = sum(1 for q in rel_queries if q['avg_relevance'] > 0.8)
        print("\nRelevance:")
        print(f"  Average: {avg_rel:.2f}")
        print(f"  Target met (>0.8): {rel_met}/{len(rel_queries)} ({rel_met/len(rel_queries)*100:.1f}%)")

    # Common queries
    query_counts = {}
    for q in queries:
        query_text = q.get('query', '')
        query_counts[query_text] = query_counts.get(query_text, 0) + 1

    print("\nTop queries:")
    for query_text, count in sorted(query_counts.items(), key=lambda x: x[1], reverse=True)[:5]:
        print(f"  {count}x: {query_text}")

    # Retrospective action items
    print("\n‚úÖ Action Items for Next Sprint:")
    if avg_time is not None and avg_time > 1000:
        print(f"  ‚Ä¢ Optimize search (current: {avg_time:.0f}ms, target: <1000ms)")
    if avg_rel is not None and avg_rel < 0.8:
        print(f"  ‚Ä¢ Improve relevance scoring (current: {avg_rel:.2f}, target: >0.8)")
    if total_hours is not None and total_hours/24.0 > 7:
        print(f"  ‚Ä¢ Increase usage intensity (queries/hour={queries_per_hour:.2f}, window>7 days)")
    elif len(queries) < 10:
        print(f"  ‚Ä¢ Increase usage (only {len(queries)} queries logged)")
    print("  ‚Ä¢ Link insights to WSJF board (--link-issue flag)")


if __name__ == '__main__':
    main()
